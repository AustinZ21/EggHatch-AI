# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=gemma3:12b

# LLM Parameters
TEMPERATURE=0.7
MAX_TOKENS=4096

# Logging
LOG_LEVEL=INFO

# Application Settings
STREAMLIT_SERVER_PORT=8501
STREAMLIT_SERVER_HEADLESS=true
